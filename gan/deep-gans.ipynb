{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from d2l import torch as d2l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@save\n",
    "d2l.DATA_HUB['pokemon'] = (d2l.DATA_URL + 'pokemon.zip',\n",
    "                           'c065c0e2593b8b161a2d7873e42418bf6a21106c')\n",
    "\n",
    "data_dir = d2l.download_extract('pokemon')\n",
    "pokemon = torchvision.datasets.ImageFolder(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "transformer = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize((64, 64)),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize(0.5, 0.5)\n",
    "])\n",
    "pokemon.transform = transformer\n",
    "data_iter = torch.utils.data.DataLoader(\n",
    "    pokemon, batch_size=batch_size,\n",
    "    shuffle=True, num_workers=d2l.get_dataloader_workers())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "d2l.set_figsize((4, 4))\n",
    "for X, y in data_iter:\n",
    "    imgs = X[:20,:,:,:].permute(0, 2, 3, 1)/2+0.5\n",
    "    d2l.show_images(imgs, num_rows=4, num_cols=5)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class G_block(nn.Module):\n",
    "    def __init__(self, out_channels, in_channels=3, kernel_size=4, strides=2,\n",
    "                 padding=1, **kwargs):\n",
    "        super(G_block, self).__init__(**kwargs)\n",
    "        self.conv2d_trans = nn.ConvTranspose2d(in_channels, out_channels,\n",
    "                                kernel_size, strides, padding, bias=False)\n",
    "        self.batch_norm = nn.BatchNorm2d(out_channels)\n",
    "        self.activation = nn.ReLU()\n",
    "\n",
    "    def forward(self, X):\n",
    "        return self.activation(self.batch_norm(self.conv2d_trans(X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.zeros((2, 3, 16, 16))\n",
    "g_blk = G_block(20)\n",
    "g_blk(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.zeros((2, 3, 1, 1))\n",
    "g_blk = G_block(20, strides=1, padding=0)\n",
    "g_blk(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_G = 64\n",
    "net_G = nn.Sequential(\n",
    "    G_block(in_channels=100, out_channels=n_G*8,\n",
    "            strides=1, padding=0),                  # Output: (64 * 8, 4, 4)\n",
    "    G_block(in_channels=n_G*8, out_channels=n_G*4), # Output: (64 * 4, 8, 8)\n",
    "    G_block(in_channels=n_G*4, out_channels=n_G*2), # Output: (64 * 2, 16, 16)\n",
    "    G_block(in_channels=n_G*2, out_channels=n_G),   # Output: (64, 32, 32)\n",
    "    nn.ConvTranspose2d(in_channels=n_G, out_channels=3,\n",
    "                       kernel_size=4, stride=2, padding=1, bias=False),\n",
    "    nn.Tanh())  # Output: (3, 64, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.zeros((1, 100, 1, 1))\n",
    "net_G(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = [0, .2, .4, .6, .8, 1]\n",
    "x = torch.arange(-2, 1, 0.1)\n",
    "Y = [nn.LeakyReLU(alpha)(x).detach().numpy() for alpha in alphas]\n",
    "d2l.plot(x.detach().numpy(), Y, 'x', 'y', alphas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class D_block(nn.Module):\n",
    "    def __init__(self, out_channels, in_channels=3, kernel_size=4, strides=2,\n",
    "                padding=1, alpha=0.2, **kwargs):\n",
    "        super(D_block, self).__init__(**kwargs)\n",
    "        self.conv2d = nn.Conv2d(in_channels, out_channels, kernel_size,\n",
    "                                strides, padding, bias=False)\n",
    "        self.batch_norm = nn.BatchNorm2d(out_channels)\n",
    "        self.activation = nn.LeakyReLU(alpha, inplace=True)\n",
    "\n",
    "    def forward(self, X):\n",
    "        return self.activation(self.batch_norm(self.conv2d(X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.zeros((2, 3, 16, 16))\n",
    "d_blk = D_block(20)\n",
    "d_blk(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_D = 64\n",
    "net_D = nn.Sequential(\n",
    "    D_block(n_D),  # Output: (64, 32, 32)\n",
    "    D_block(in_channels=n_D, out_channels=n_D*2),  # Output: (64 * 2, 16, 16)\n",
    "    D_block(in_channels=n_D*2, out_channels=n_D*4),  # Output: (64 * 4, 8, 8)\n",
    "    D_block(in_channels=n_D*4, out_channels=n_D*8),  # Output: (64 * 8, 4, 4)\n",
    "    nn.Conv2d(in_channels=n_D*8, out_channels=1,\n",
    "              kernel_size=4, bias=False))  # Output: (1, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.zeros((1, 3, 64, 64))\n",
    "net_D(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net_D, net_G, data_iter, num_epochs, lr, latent_dim,\n",
    "          device=d2l.try_gpu()):\n",
    "    loss = nn.BCEWithLogitsLoss(reduction='sum')\n",
    "    for w in net_D.parameters():\n",
    "        nn.init.normal_(w, 0, 0.02)\n",
    "    for w in net_G.parameters():\n",
    "        nn.init.normal_(w, 0, 0.02)\n",
    "    net_D, net_G = net_D.to(device), net_G.to(device)\n",
    "    trainer_hp = {'lr': lr, 'betas': [0.5,0.999]}\n",
    "    trainer_D = torch.optim.Adam(net_D.parameters(), **trainer_hp)\n",
    "    trainer_G = torch.optim.Adam(net_G.parameters(), **trainer_hp)\n",
    "    animator = d2l.Animator(xlabel='epoch', ylabel='loss',\n",
    "                            xlim=[1, num_epochs], nrows=2, figsize=(5, 5),\n",
    "                            legend=['discriminator', 'generator'])\n",
    "    animator.fig.subplots_adjust(hspace=0.3)\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        # Train one epoch\n",
    "        timer = d2l.Timer()\n",
    "        metric = d2l.Accumulator(3)  # loss_D, loss_G, num_examples\n",
    "        for X, _ in data_iter:\n",
    "            batch_size = X.shape[0]\n",
    "            Z = torch.normal(0, 1, size=(batch_size, latent_dim, 1, 1))\n",
    "            X, Z = X.to(device), Z.to(device)\n",
    "            metric.add(d2l.update_D(X, Z, net_D, net_G, loss, trainer_D),\n",
    "                       d2l.update_G(Z, net_D, net_G, loss, trainer_G),\n",
    "                       batch_size)\n",
    "        # Show generated examples\n",
    "        Z = torch.normal(0, 1, size=(21, latent_dim, 1, 1), device=device)\n",
    "        # Normalize the synthetic data to N(0, 1)\n",
    "        fake_x = net_G(Z).permute(0, 2, 3, 1) / 2 + 0.5\n",
    "        imgs = torch.cat(\n",
    "            [torch.cat([\n",
    "                fake_x[i * 7 + j].cpu().detach() for j in range(7)], dim=1)\n",
    "             for i in range(len(fake_x)//7)], dim=0)\n",
    "        animator.axes[1].cla()\n",
    "        animator.axes[1].imshow(imgs)\n",
    "        # Show the losses\n",
    "        loss_D, loss_G = metric[0] / metric[2], metric[1] / metric[2]\n",
    "        animator.add(epoch, (loss_D, loss_G))\n",
    "    print(f'loss_D {loss_D:.3f}, loss_G {loss_G:.3f}, '\n",
    "          f'{metric[2] / timer.stop():.1f} examples/sec on {str(device)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim, lr, num_epochs = 100, 0.005, 20\n",
    "train(net_D, net_G, data_iter, num_epochs, lr, latent_dim)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit ('3.8.3')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bb73a0d18186632bad5efb9cd0e6626324154d096ec0de1fe81e099ffeea3aaa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
